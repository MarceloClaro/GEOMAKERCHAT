import streamlit as st
import os
import pandas as pd
from langchain.llms import GroqLLM  # Atualizado para usar a interface correta
from langchain.prompts import ChatPrompt
from langchain.runnables import RunnableSequence

def upload_data():
    uploaded_files = st.file_uploader("Fa√ßa upload dos seus arquivos (JSON ou CSV, at√© 300MB cada)", type=['json', 'csv'], accept_multiple_files=True)
    data_frames = []
    if uploaded_files:
        for file in uploaded_files:
            try:
                data = pd.read_json(file) if file.type == "application/json" else pd.read_csv(file)
                data_frames.append(data)
                st.session_state[file.name] = data
                st.write(f"Pr√©-visualiza√ß√£o do arquivo {file.name} carregado:")
                st.dataframe(data.head())
            except Exception as e:
                st.error(f"Erro ao processar o arquivo {file.name}: {e}")
    return data_frames

def main():
    st.set_page_config(page_icon="üí¨", layout="wide", page_title="Interface de Chat Avan√ßado com RAG")
    st.title("Bem-vindo ao Chat Avan√ßado com RAG!")
    st.write("Este chatbot utiliza um modelo avan√ßado que combina gera√ß√£o de linguagem com recupera√ß√£o de informa√ß√µes.")

    groq_api_key = os.getenv('GROQ_API_KEY', 'Chave_API_Padr√£o')
    model = GroqLLM(api_key=groq_api_key)  # Usando o novo m√©todo para criar uma inst√¢ncia LLM
    data_frames = upload_data()

    if 'chat_history' not in st.session_state:
        st.session_state['chat_history'] = []

    primary_prompt = "Como posso ajudar voc√™ hoje?"
    secondary_prompt = "H√° algo mais em que posso ajudar?"

    user_question = st.text_input("Fa√ßa uma pergunta:")
    if user_question:
        current_prompt = secondary_prompt if st.session_state.get('last_prompt', primary_prompt) == primary_prompt else primary_prompt
        st.session_state['last_prompt'] = current_prompt

        prompt = ChatPrompt(content=current_prompt)
        sequence = RunnableSequence([
            prompt,  # Prompt que prepara a pergunta
            model    # LLM que processa a entrada
        ])

        response = sequence.run(user_input=user_question, chat_history=st.session_state['chat_history'])
        message = {'human': user_question, 'AI': response}
        st.session_state.chat_history.append(message)
        st.write("Chatbot:", response)

if __name__ == "__main__":
    main()

